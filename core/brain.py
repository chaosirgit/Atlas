import os
import json
from typing import Dict, Any, List
import dashscope
from dashscope import Generation
from .memory import Memory
from .tool_manager import AtlasTools
from .config import SYSTEM_PROMPT

dashscope.api_key = os.getenv('DASHSCOPE_API_KEY')


class AtlasBrain:
    """Atlasçš„å¤§è„‘ - æ•´åˆåƒé—®ã€è®°å¿†å’Œå·¥å…·"""

    def __init__(self, debug: bool = False):
        self.memory = Memory()
        self.tools = AtlasTools()
        self.system_prompt = SYSTEM_PROMPT
        self.debug = debug  # è°ƒè¯•å¼€å…³

    def _parse_tool_call(self, response: str) -> List[Dict[str, Any]]:
        """è§£æAIè¿”å›çš„å·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒå¤šä¸ªï¼‰"""
        try:
            # å…ˆå°è¯•æå–ä»£ç å—ä¸­çš„JSON
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0].strip()
            else:
                # ğŸ”¥ æ–°å¢ï¼šå¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå›å¤
                json_str = response.strip()

            tool_calls = json.loads(json_str)

            # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨
            if isinstance(tool_calls, dict):
                return [tool_calls]
            elif isinstance(tool_calls, list):
                return tool_calls
            else:
                return None
        except Exception as e:
            return None

    def _execute_tool(self, tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        action = tool_call.get('action')
        params = tool_call.get('parameters', {})

        tool_map = {
            'create_directory': self.tools.create_directory,
            'delete_directory': self.tools.delete_directory,
            'create_file': self.tools.create_file,
            'delete_file': self.tools.delete_file,
            'move_directory': self.tools.move_directory,
            'move_file': self.tools.move_file,
            'write_file': self.tools.write_file,
            'read_file': self.tools.read_file,
            'list_directory': self.tools.list_directory,
            'execute_python': self.tools.execute_python,
            'read_web_content': self.tools.read_web_content,
            'list_web_resources': self.tools.list_web_resources,
            'get_current_location': self.tools.get_current_location,
            'get_weather': self.tools.get_weather,
        }

        if action in tool_map:
            return tool_map[action](**params)
        else:
            return {"success": False, "message": f"æœªçŸ¥å·¥å…·: {action}"}

    def think(self, user_input: str) -> str:
        """ä¸»æ€è€ƒå‡½æ•° - å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›å“åº”"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°è®°å¿†
        self.memory.add_message('user', user_input)

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«ç›¸å…³çš„é•¿æœŸè®°å¿†ï¼‰
        messages = [{'role': 'system', 'content': self.system_prompt}]
        messages.extend(self.memory.format_for_qwen(include_long_term=True, query=user_input))

        # è°ƒç”¨åƒé—®
        response = Generation.call(
            model='qwen3-max',
            messages=messages,
            result_format='message'
        )

        ai_response = response.output.choices[0].message.content

        if self.debug:
            print(f"\n{'=' * 50}")
            print(f"[DEBUG] AIåŸå§‹å›å¤:\n{ai_response}")
            print(f"{'=' * 50}\n")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·
        tool_calls = self._parse_tool_call(ai_response)

        if self.debug:
            print(f"[DEBUG] è§£æåˆ°çš„å·¥å…·è°ƒç”¨: {tool_calls}\n")

        if tool_calls:
            # æ‰§è¡Œæ‰€æœ‰å·¥å…·
            results = []
            thoughts = []

            for tool_call in tool_calls:
                thought = tool_call.get('thought', '')
                thoughts.append(thought)
                tool_result = self._execute_tool(tool_call)
                results.append(tool_result)

                if self.debug:
                    print(f"[DEBUG] æ‰§è¡Œ {tool_call.get('action')}: {tool_result}\n")

            # å°†å·¥å…·æ‰§è¡Œç»“æœåé¦ˆç»™AI
            feedback = f"å·¥å…·æ‰§è¡Œç»“æœ: {json.dumps(results, ensure_ascii=False)}"
            self.memory.add_message('assistant', ai_response)
            self.memory.add_message('system', feedback)

            # è®©AIæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
            messages = [{'role': 'system', 'content': self.system_prompt}]
            messages.extend(self.memory.format_for_qwen(include_long_term=False))

            final_response = Generation.call(
                model='qwen3-max',
                messages=messages,
                result_format='message'
            )

            final_answer = final_response.output.choices[0].message.content
            self.memory.add_message('assistant', final_answer)

            # æ ¼å¼åŒ–è¾“å‡º
            thoughts_str = "\n".join([f"  {i + 1}. {t}" for i, t in enumerate(thoughts)])
            results_str = "\n".join([f"  {i + 1}. {r['message']}" for i, r in enumerate(results)])

            return f"ğŸ’­ æ€è€ƒ:\n{thoughts_str}\n\nğŸ”§ æ‰§è¡Œ:\n{results_str}\n\nâœ… {final_answer}"
        else:
            # æ™®é€šå¯¹è¯
            self.memory.add_message('assistant', ai_response)
            return ai_response


    def get_memory_summary(self) -> str:
        """è·å–è®°å¿†æ‘˜è¦"""
        convs = self.memory.get_all_conversations()
        return f"å…±æœ‰ {len(convs)} æ¡å¯¹è¯è®°å½•"


    def clear_memory(self):
        """æ¸…ç©ºè®°å¿†"""
        self.memory.clear_memory()